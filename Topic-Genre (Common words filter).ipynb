{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "07739fe5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                          Cleaned_Lyrics  Genre  \\\n",
      "0      Red dragon from the first morning of time\\nRed...  Metal   \n",
      "1      Broad incision sits across the evening\\nA vict...  Metal   \n",
      "2      I dont wanna see\\nI dont wanna say\\nTime stand...  Metal   \n",
      "3      Weve walked together down this winding road\\nI...  Metal   \n",
      "4      Brothers the battle is raging choose your side...  Metal   \n",
      "...                                                  ...    ...   \n",
      "47995  Intro\\nYou did it baby Congratulations homie\\n...    Rap   \n",
      "47996  Tah Murdah\\nPerminently dedicated to the stree...    Rap   \n",
      "47997  Intro\\nCompton in the house\\n\\n\\nChorus DJ Qui...    Rap   \n",
      "47998  Bizzy\\nThere is no way in hell marching factio...    Rap   \n",
      "47999  Produced by Tae Beast\\n\\nIntro\\nMake sure the ...    Rap   \n",
      "\n",
      "       topic_dominant  \n",
      "0                   3  \n",
      "1                   9  \n",
      "2                   1  \n",
      "3                   1  \n",
      "4                   9  \n",
      "...               ...  \n",
      "47995               8  \n",
      "47996               8  \n",
      "47997               8  \n",
      "47998               8  \n",
      "47999               2  \n",
      "\n",
      "[47998 rows x 3 columns]\n",
      "Cuvintele pentru fiecare topic (fără filtrare):\n",
      "Topic 0: love, la, just, day, song, sweet, sing, blue, come, like, little, happy, im, heart, oh, got, man, dream, night, old\n",
      "Topic 1: im, love, dont, know, just, time, youre, away, life, ill, feel, let, way, ive, heart, like, say, day, cause, make\n",
      "Topic 2: like, yo, im, rock, got, verse, new, cause, man, yall, ya, beat, check, mic, just, thats, time, rap, know, rhymes\n",
      "Topic 3: sky, high, moon, night, sun, light, eyes, love, boom, come, stars, oh, sea, fly, rain, shine, hear, girls, like, dem\n",
      "Topic 4: im, like, dont, just, got, aint, know, cause, man, verse, fuck, shit, say, thats, think, right, yeah, hook, said, make\n",
      "Topic 5: like, na, just, dance, lets, shes, party, round, shake, hands, let, time, night, make, head, heart, body, love, im, roll\n",
      "Topic 6: la, les, le, que, et, je, pas, pour, des, en, cest, tu, du, dans, qui, bye, ma, mon, est, se\n",
      "Topic 7: oh, baby, yeah, im, dont, know, girl, got, like, wanna, want, love, youre, just, hey, gonna, cause, come, make, right\n",
      "Topic 8: im, nigga, like, niggas, got, aint, shit, dont, know, ya, fuck, em, bitch, money, verse, cause, yall, thats, yeah, yo\n",
      "Topic 9: blood, god, death, world, war, people, dead, black, life, like, die, kill, hell, man, power, born, fight, time, fear, pain\n",
      "Cuvintele pentru fiecare topic (cu filtrare):\n",
      "Topic 0: song, sweet, sing, blue, little, happy, dream, old\n",
      "Topic 1: away, ill, feel, way, ive\n",
      "Topic 2: rock, new, beat, check, mic, rap, rhymes\n",
      "Topic 3: sky, high, moon, sun, light, eyes, boom, stars, sea, fly, rain, shine, hear, girls, dem\n",
      "Topic 4: think, hook, said\n",
      "Topic 5: na, dance, lets, shes, party, round, shake, hands, head, body, roll\n",
      "Topic 6: les, le, que, et, je, pas, pour, des, en, cest, tu, du, dans, qui, bye, ma, mon, est, se\n",
      "Topic 7: baby, girl, wanna, want, hey, gonna\n",
      "Topic 8: nigga, niggas, em, bitch, money\n",
      "Topic 9: blood, god, death, world, war, people, dead, black, die, kill, hell, power, born, fight, fear, pain\n",
      "topic_dominant     0     1     2     3     4    5    6     7     8     9\n",
      "Genre                                                                   \n",
      "Jazz            3467  4618   266  1103   393  575   78  1161   121   218\n",
      "Metal            148  7085   101   336   578  155   27   364   117  3089\n",
      "Pop              562  5344   170   297  1038  329   65  2611  1276   308\n",
      "Rap               36   467  1524    35  3174   51  186   483  5389   653\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.decomposition import LatentDirichletAllocation\n",
    "\n",
    "# Încarcă setul de date\n",
    "data = pd.read_csv('12000_lyrics_dataset.csv')\n",
    "\n",
    "# Elimină rândurile cu valori NaN în coloana 'Cleaned_Lyrics'\n",
    "data = data.dropna(subset=['Cleaned_Lyrics'])\n",
    "\n",
    "# Initializează vectorizatorul și modelul LDA\n",
    "vectorizer = CountVectorizer(max_df=0.95, min_df=2, stop_words='english')\n",
    "lda = LatentDirichletAllocation(n_components=10, random_state=0)\n",
    "\n",
    "# Vectorizează textele din coloana 'Cleaned_Lyrics'\n",
    "X = vectorizer.fit_transform(data['Cleaned_Lyrics'])\n",
    "\n",
    "# Antrenează modelul LDA pe datele vectorizate\n",
    "lda.fit(X)\n",
    "\n",
    "# Obține distribuția topic-urilor pentru fiecare instanță de versuri\n",
    "topic_distributions = lda.transform(X)\n",
    "\n",
    "# Identifică topic-ul dominant pentru fiecare instanță\n",
    "dominant_topics = topic_distributions.argmax(axis=1)\n",
    "\n",
    "# Adaugă topic-ul dominant la setul de date original\n",
    "data['topic_dominant'] = dominant_topics\n",
    "\n",
    "# Afișează rezultatele inițiale\n",
    "print(data[['Cleaned_Lyrics', 'Genre', 'topic_dominant']])\n",
    "\n",
    "# Funcție pentru a obține cuvintele cele mai relevante pentru fiecare topic\n",
    "def get_top_words(model, feature_names, n_top_words):\n",
    "    top_words = {}\n",
    "    for topic_idx, topic in enumerate(model.components_):\n",
    "        top_words[topic_idx] = [feature_names[i] for i in topic.argsort()[:-n_top_words - 1:-1]]\n",
    "    return top_words\n",
    "\n",
    "# Obține cuvintele corespunzătoare fiecărui topic\n",
    "feature_names = vectorizer.get_feature_names_out()\n",
    "top_words = get_top_words(lda, feature_names, 20)\n",
    "\n",
    "# Afișează cuvintele pentru fiecare topic (fără filtrare)\n",
    "print(\"Cuvintele pentru fiecare topic (fără filtrare):\")\n",
    "for topic, words in top_words.items():\n",
    "    print(f\"Topic {topic}: {', '.join(words)}\")\n",
    "\n",
    "# Salvează cuvintele pentru fiecare topic (fără filtrare) într-un fișier CSV\n",
    "with open('12000_top_words_without_filtering.csv', 'w') as f:\n",
    "    f.write(\"Topic,Words\\n\")\n",
    "    for topic, words in top_words.items():\n",
    "        f.write(f\"{topic},{', '.join(words)}\\n\")\n",
    "\n",
    "# Identifică cuvintele comune între topicuri\n",
    "word_counts = {}\n",
    "for words in top_words.values():\n",
    "    for word in words:\n",
    "        word_counts[word] = word_counts.get(word, 0) + 1\n",
    "\n",
    "# Elimină cuvintele comune între topicuri\n",
    "unique_top_words = {}\n",
    "for topic_idx, words in top_words.items():\n",
    "    unique_top_words[topic_idx] = [word for word in words if word_counts[word] == 1]\n",
    "\n",
    "# Afișează cuvintele filtrate pentru fiecare topic\n",
    "print(\"Cuvintele pentru fiecare topic (cu filtrare):\")\n",
    "for topic, words in unique_top_words.items():\n",
    "    print(f\"Topic {topic}: {', '.join(words)}\")\n",
    "\n",
    "# Salvează cuvintele pentru fiecare topic (cu filtrare) într-un fișier CSV\n",
    "with open('12000_top_words_with_filtering.csv', 'w') as f:\n",
    "    f.write(\"Topic,Words\\n\")\n",
    "    for topic, words in unique_top_words.items():\n",
    "        f.write(f\"{topic},{', '.join(words)}\\n\")\n",
    "\n",
    "# Analiza frecvenței topicurilor pe genuri\n",
    "topic_genre_distribution = data.groupby(['Genre', 'topic_dominant']).size().unstack(fill_value=0)\n",
    "\n",
    "# Afișează distribuția topicurilor pe genuri\n",
    "print(topic_genre_distribution)\n",
    "\n",
    "# Salvează distribuția topicurilor pe genuri într-un fișier CSV\n",
    "topic_genre_distribution.to_csv('12000_topic_genre_distribution.csv')\n",
    "\n",
    "# Salvează setul de date original cu topicurile dominante într-un fișier CSV\n",
    "data.to_csv('12000_lyrics_with_topics.csv', index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "242d44a5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: pyLDAvis in c:\\users\\admin\\anaconda3\\lib\\site-packages (3.4.1)\n",
      "Requirement already satisfied: numpy>=1.24.2 in c:\\users\\admin\\anaconda3\\lib\\site-packages (from pyLDAvis) (1.24.3)\n",
      "Requirement already satisfied: scipy in c:\\users\\admin\\anaconda3\\lib\\site-packages (from pyLDAvis) (1.11.1)\n",
      "Requirement already satisfied: pandas>=2.0.0 in c:\\users\\admin\\anaconda3\\lib\\site-packages (from pyLDAvis) (2.0.3)\n",
      "Requirement already satisfied: joblib>=1.2.0 in c:\\users\\admin\\anaconda3\\lib\\site-packages (from pyLDAvis) (1.2.0)\n",
      "Requirement already satisfied: jinja2 in c:\\users\\admin\\anaconda3\\lib\\site-packages (from pyLDAvis) (3.1.2)\n",
      "Requirement already satisfied: numexpr in c:\\users\\admin\\anaconda3\\lib\\site-packages (from pyLDAvis) (2.8.4)\n",
      "Requirement already satisfied: funcy in c:\\users\\admin\\anaconda3\\lib\\site-packages (from pyLDAvis) (2.0)\n",
      "Requirement already satisfied: scikit-learn>=1.0.0 in c:\\users\\admin\\anaconda3\\lib\\site-packages (from pyLDAvis) (1.3.0)\n",
      "Requirement already satisfied: gensim in c:\\users\\admin\\anaconda3\\lib\\site-packages (from pyLDAvis) (4.3.0)\n",
      "Requirement already satisfied: setuptools in c:\\users\\admin\\anaconda3\\lib\\site-packages (from pyLDAvis) (68.0.0)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in c:\\users\\admin\\anaconda3\\lib\\site-packages (from pandas>=2.0.0->pyLDAvis) (2.8.2)\n",
      "Requirement already satisfied: pytz>=2020.1 in c:\\users\\admin\\anaconda3\\lib\\site-packages (from pandas>=2.0.0->pyLDAvis) (2023.3.post1)\n",
      "Requirement already satisfied: tzdata>=2022.1 in c:\\users\\admin\\anaconda3\\lib\\site-packages (from pandas>=2.0.0->pyLDAvis) (2023.3)\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in c:\\users\\admin\\anaconda3\\lib\\site-packages (from scikit-learn>=1.0.0->pyLDAvis) (2.2.0)\n",
      "Requirement already satisfied: smart-open>=1.8.1 in c:\\users\\admin\\anaconda3\\lib\\site-packages (from gensim->pyLDAvis) (5.2.1)\n",
      "Requirement already satisfied: FuzzyTM>=0.4.0 in c:\\users\\admin\\anaconda3\\lib\\site-packages (from gensim->pyLDAvis) (2.0.5)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in c:\\users\\admin\\anaconda3\\lib\\site-packages (from jinja2->pyLDAvis) (2.1.1)\n",
      "Requirement already satisfied: pyfume in c:\\users\\admin\\anaconda3\\lib\\site-packages (from FuzzyTM>=0.4.0->gensim->pyLDAvis) (0.2.25)\n",
      "Requirement already satisfied: six>=1.5 in c:\\users\\admin\\anaconda3\\lib\\site-packages (from python-dateutil>=2.8.2->pandas>=2.0.0->pyLDAvis) (1.16.0)\n",
      "Requirement already satisfied: simpful in c:\\users\\admin\\anaconda3\\lib\\site-packages (from pyfume->FuzzyTM>=0.4.0->gensim->pyLDAvis) (2.11.0)\n",
      "Requirement already satisfied: fst-pso in c:\\users\\admin\\anaconda3\\lib\\site-packages (from pyfume->FuzzyTM>=0.4.0->gensim->pyLDAvis) (1.8.1)\n",
      "Requirement already satisfied: miniful in c:\\users\\admin\\anaconda3\\lib\\site-packages (from fst-pso->pyfume->FuzzyTM>=0.4.0->gensim->pyLDAvis) (0.0.6)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install pyLDAvis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "e2a6319a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: pyLDAvis in c:\\users\\admin\\anaconda3\\lib\\site-packages (3.4.1)\n",
      "Requirement already satisfied: gensim in c:\\users\\admin\\anaconda3\\lib\\site-packages (4.3.0)\n",
      "Requirement already satisfied: numpy>=1.24.2 in c:\\users\\admin\\anaconda3\\lib\\site-packages (from pyLDAvis) (1.24.3)\n",
      "Requirement already satisfied: scipy in c:\\users\\admin\\anaconda3\\lib\\site-packages (from pyLDAvis) (1.11.1)\n",
      "Requirement already satisfied: pandas>=2.0.0 in c:\\users\\admin\\anaconda3\\lib\\site-packages (from pyLDAvis) (2.0.3)\n",
      "Requirement already satisfied: joblib>=1.2.0 in c:\\users\\admin\\anaconda3\\lib\\site-packages (from pyLDAvis) (1.2.0)\n",
      "Requirement already satisfied: jinja2 in c:\\users\\admin\\anaconda3\\lib\\site-packages (from pyLDAvis) (3.1.2)\n",
      "Requirement already satisfied: numexpr in c:\\users\\admin\\anaconda3\\lib\\site-packages (from pyLDAvis) (2.8.4)\n",
      "Requirement already satisfied: funcy in c:\\users\\admin\\anaconda3\\lib\\site-packages (from pyLDAvis) (2.0)\n",
      "Requirement already satisfied: scikit-learn>=1.0.0 in c:\\users\\admin\\anaconda3\\lib\\site-packages (from pyLDAvis) (1.3.0)\n",
      "Requirement already satisfied: setuptools in c:\\users\\admin\\anaconda3\\lib\\site-packages (from pyLDAvis) (68.0.0)\n",
      "Requirement already satisfied: smart-open>=1.8.1 in c:\\users\\admin\\anaconda3\\lib\\site-packages (from gensim) (5.2.1)\n",
      "Requirement already satisfied: FuzzyTM>=0.4.0 in c:\\users\\admin\\anaconda3\\lib\\site-packages (from gensim) (2.0.5)\n",
      "Requirement already satisfied: pyfume in c:\\users\\admin\\anaconda3\\lib\\site-packages (from FuzzyTM>=0.4.0->gensim) (0.2.25)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in c:\\users\\admin\\anaconda3\\lib\\site-packages (from pandas>=2.0.0->pyLDAvis) (2.8.2)\n",
      "Requirement already satisfied: pytz>=2020.1 in c:\\users\\admin\\anaconda3\\lib\\site-packages (from pandas>=2.0.0->pyLDAvis) (2023.3.post1)\n",
      "Requirement already satisfied: tzdata>=2022.1 in c:\\users\\admin\\anaconda3\\lib\\site-packages (from pandas>=2.0.0->pyLDAvis) (2023.3)\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in c:\\users\\admin\\anaconda3\\lib\\site-packages (from scikit-learn>=1.0.0->pyLDAvis) (2.2.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in c:\\users\\admin\\anaconda3\\lib\\site-packages (from jinja2->pyLDAvis) (2.1.1)\n",
      "Requirement already satisfied: six>=1.5 in c:\\users\\admin\\anaconda3\\lib\\site-packages (from python-dateutil>=2.8.2->pandas>=2.0.0->pyLDAvis) (1.16.0)\n",
      "Requirement already satisfied: simpful in c:\\users\\admin\\anaconda3\\lib\\site-packages (from pyfume->FuzzyTM>=0.4.0->gensim) (2.11.0)\n",
      "Requirement already satisfied: fst-pso in c:\\users\\admin\\anaconda3\\lib\\site-packages (from pyfume->FuzzyTM>=0.4.0->gensim) (1.8.1)\n",
      "Requirement already satisfied: miniful in c:\\users\\admin\\anaconda3\\lib\\site-packages (from fst-pso->pyfume->FuzzyTM>=0.4.0->gensim) (0.0.6)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install pyLDAvis gensim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "f171423d",
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'LatentDirichletAllocation' object has no attribute 'num_topics'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[9], line 14\u001b[0m\n\u001b[0;32m     12\u001b[0m \u001b[38;5;66;03m# Vizualizarea topicurilor cu pyLDAvis\u001b[39;00m\n\u001b[0;32m     13\u001b[0m pyLDAvis\u001b[38;5;241m.\u001b[39menable_notebook()\n\u001b[1;32m---> 14\u001b[0m lda_display \u001b[38;5;241m=\u001b[39m gensimvis\u001b[38;5;241m.\u001b[39mprepare(lda, corpus, id2word, sort_topics\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)\n\u001b[0;32m     16\u001b[0m \u001b[38;5;66;03m# Afișează vizualizarea\u001b[39;00m\n\u001b[0;32m     17\u001b[0m pyLDAvis\u001b[38;5;241m.\u001b[39mshow(lda_display)\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\pyLDAvis\\gensim_models.py:122\u001b[0m, in \u001b[0;36mprepare\u001b[1;34m(topic_model, corpus, dictionary, doc_topic_dist, **kwargs)\u001b[0m\n\u001b[0;32m     77\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mprepare\u001b[39m(topic_model, corpus, dictionary, doc_topic_dist\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[0;32m     78\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Transforms the Gensim TopicModel and related corpus and dictionary into\u001b[39;00m\n\u001b[0;32m     79\u001b[0m \u001b[38;5;124;03m    the data structures needed for the visualization.\u001b[39;00m\n\u001b[0;32m     80\u001b[0m \n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    120\u001b[0m \u001b[38;5;124;03m    See `pyLDAvis.prepare` for **kwargs.\u001b[39;00m\n\u001b[0;32m    121\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m--> 122\u001b[0m     opts \u001b[38;5;241m=\u001b[39m fp\u001b[38;5;241m.\u001b[39mmerge(_extract_data(topic_model, corpus, dictionary, doc_topic_dist), kwargs)\n\u001b[0;32m    123\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m pyLDAvis\u001b[38;5;241m.\u001b[39mprepare(\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mopts)\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\pyLDAvis\\gensim_models.py:42\u001b[0m, in \u001b[0;36m_extract_data\u001b[1;34m(topic_model, corpus, dictionary, doc_topic_dists)\u001b[0m\n\u001b[0;32m     40\u001b[0m     num_topics \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlen\u001b[39m(topic_model\u001b[38;5;241m.\u001b[39mlda_alpha)\n\u001b[0;32m     41\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m---> 42\u001b[0m     num_topics \u001b[38;5;241m=\u001b[39m topic_model\u001b[38;5;241m.\u001b[39mnum_topics\n\u001b[0;32m     44\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m doc_topic_dists \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m     45\u001b[0m     \u001b[38;5;66;03m# If its an HDP model.\u001b[39;00m\n\u001b[0;32m     46\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(topic_model, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mlda_beta\u001b[39m\u001b[38;5;124m'\u001b[39m):\n",
      "\u001b[1;31mAttributeError\u001b[0m: 'LatentDirichletAllocation' object has no attribute 'num_topics'"
     ]
    }
   ],
   "source": [
    "import pyLDAvis\n",
    "import pyLDAvis.gensim_models as gensimvis\n",
    "import gensim\n",
    "from gensim.matutils import Sparse2Corpus\n",
    "from gensim.corpora import Dictionary\n",
    "\n",
    "\n",
    "# Convert CountVectorizer result to a Gensim corpus and dictionary\n",
    "corpus = Sparse2Corpus(X, documents_columns=False)\n",
    "id2word = Dictionary.from_corpus(corpus, id2word=dict((i, s) for i, s in enumerate(vectorizer.get_feature_names_out())))\n",
    "\n",
    "# Vizualizarea topicurilor cu pyLDAvis\n",
    "pyLDAvis.enable_notebook()\n",
    "lda_display = gensimvis.prepare(lda, corpus, id2word, sort_topics=False)\n",
    "\n",
    "# Afișează vizualizarea\n",
    "pyLDAvis.show(lda_display)\n",
    "\n",
    "# Salvează vizualizarea în format HTML pentru a putea fi accesată ulterior\n",
    "pyLDAvis.save_html(lda_display, '12000_lda_visualization.html')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "dac995bb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                          Cleaned_Lyrics  Genre  \\\n",
      "0      Red dragon from the first morning of time\\nRed...  Metal   \n",
      "1      Broad incision sits across the evening\\nA vict...  Metal   \n",
      "2      I dont wanna see\\nI dont wanna say\\nTime stand...  Metal   \n",
      "3      Weve walked together down this winding road\\nI...  Metal   \n",
      "4      Brothers the battle is raging choose your side...  Metal   \n",
      "...                                                  ...    ...   \n",
      "47995  Intro\\nYou did it baby Congratulations homie\\n...    Rap   \n",
      "47996  Tah Murdah\\nPerminently dedicated to the stree...    Rap   \n",
      "47997  Intro\\nCompton in the house\\n\\n\\nChorus DJ Qui...    Rap   \n",
      "47998  Bizzy\\nThere is no way in hell marching factio...    Rap   \n",
      "47999  Produced by Tae Beast\\n\\nIntro\\nMake sure the ...    Rap   \n",
      "\n",
      "       topic_dominant  \n",
      "0                   3  \n",
      "1                   9  \n",
      "2                   1  \n",
      "3                   1  \n",
      "4                   9  \n",
      "...               ...  \n",
      "47995               8  \n",
      "47996               8  \n",
      "47997               8  \n",
      "47998               8  \n",
      "47999               2  \n",
      "\n",
      "[47998 rows x 3 columns]\n",
      "Cuvintele pentru fiecare topic (fără filtrare):\n",
      "Topic 0: love, la, just, day, song, sweet, sing, blue, come, like, little, happy, im, heart, oh, got, man, dream, night, old\n",
      "Topic 1: im, love, dont, know, just, time, youre, away, life, ill, feel, let, way, ive, heart, like, say, day, cause, make\n",
      "Topic 2: like, yo, im, rock, got, verse, new, cause, man, yall, ya, beat, check, mic, just, thats, time, rap, know, rhymes\n",
      "Topic 3: sky, high, moon, night, sun, light, eyes, love, boom, come, stars, oh, sea, fly, rain, shine, hear, girls, like, dem\n",
      "Topic 4: im, like, dont, just, got, aint, know, cause, man, verse, fuck, shit, say, thats, think, right, yeah, hook, said, make\n",
      "Topic 5: like, na, just, dance, lets, shes, party, round, shake, hands, let, time, night, make, head, heart, body, love, im, roll\n",
      "Topic 6: la, les, le, que, et, je, pas, pour, des, en, cest, tu, du, dans, qui, bye, ma, mon, est, se\n",
      "Topic 7: oh, baby, yeah, im, dont, know, girl, got, like, wanna, want, love, youre, just, hey, gonna, cause, come, make, right\n",
      "Topic 8: im, nigga, like, niggas, got, aint, shit, dont, know, ya, fuck, em, bitch, money, verse, cause, yall, thats, yeah, yo\n",
      "Topic 9: blood, god, death, world, war, people, dead, black, life, like, die, kill, hell, man, power, born, fight, time, fear, pain\n",
      "Cuvintele pentru fiecare topic (cu filtrare):\n",
      "Topic 0: song, sweet, sing, blue, little, happy, dream, old\n",
      "Topic 1: away, ill, feel, way, ive\n",
      "Topic 2: rock, new, beat, check, mic, rap, rhymes\n",
      "Topic 3: sky, high, moon, sun, light, eyes, boom, stars, sea, fly, rain, shine, hear, girls, dem\n",
      "Topic 4: think, hook, said\n",
      "Topic 5: na, dance, lets, shes, party, round, shake, hands, head, body, roll\n",
      "Topic 6: les, le, que, et, je, pas, pour, des, en, cest, tu, du, dans, qui, bye, ma, mon, est, se\n",
      "Topic 7: baby, girl, wanna, want, hey, gonna\n",
      "Topic 8: nigga, niggas, em, bitch, money\n",
      "Topic 9: blood, god, death, world, war, people, dead, black, die, kill, hell, power, born, fight, fear, pain\n",
      "topic_dominant     0     1     2     3     4    5    6     7     8     9\n",
      "Genre                                                                   \n",
      "Jazz            3467  4618   266  1103   393  575   78  1161   121   218\n",
      "Metal            148  7085   101   336   578  155   27   364   117  3089\n",
      "Pop              562  5344   170   297  1038  329   65  2611  1276   308\n",
      "Rap               36   467  1524    35  3174   51  186   483  5389   653\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "'LatentDirichletAllocation' object has no attribute 'num_topics'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[10], line 100\u001b[0m\n\u001b[0;32m     98\u001b[0m \u001b[38;5;66;03m# Vizualizarea topicurilor cu pyLDAvis\u001b[39;00m\n\u001b[0;32m     99\u001b[0m pyLDAvis\u001b[38;5;241m.\u001b[39menable_notebook()\n\u001b[1;32m--> 100\u001b[0m lda_display \u001b[38;5;241m=\u001b[39m gensimvis\u001b[38;5;241m.\u001b[39mprepare(lda, corpus, id2word, sort_topics\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)\n\u001b[0;32m    102\u001b[0m \u001b[38;5;66;03m# Afișează vizualizarea\u001b[39;00m\n\u001b[0;32m    103\u001b[0m pyLDAvis\u001b[38;5;241m.\u001b[39mshow(lda_display)\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\pyLDAvis\\gensim_models.py:122\u001b[0m, in \u001b[0;36mprepare\u001b[1;34m(topic_model, corpus, dictionary, doc_topic_dist, **kwargs)\u001b[0m\n\u001b[0;32m     77\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mprepare\u001b[39m(topic_model, corpus, dictionary, doc_topic_dist\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[0;32m     78\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Transforms the Gensim TopicModel and related corpus and dictionary into\u001b[39;00m\n\u001b[0;32m     79\u001b[0m \u001b[38;5;124;03m    the data structures needed for the visualization.\u001b[39;00m\n\u001b[0;32m     80\u001b[0m \n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    120\u001b[0m \u001b[38;5;124;03m    See `pyLDAvis.prepare` for **kwargs.\u001b[39;00m\n\u001b[0;32m    121\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m--> 122\u001b[0m     opts \u001b[38;5;241m=\u001b[39m fp\u001b[38;5;241m.\u001b[39mmerge(_extract_data(topic_model, corpus, dictionary, doc_topic_dist), kwargs)\n\u001b[0;32m    123\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m pyLDAvis\u001b[38;5;241m.\u001b[39mprepare(\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mopts)\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\pyLDAvis\\gensim_models.py:42\u001b[0m, in \u001b[0;36m_extract_data\u001b[1;34m(topic_model, corpus, dictionary, doc_topic_dists)\u001b[0m\n\u001b[0;32m     40\u001b[0m     num_topics \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlen\u001b[39m(topic_model\u001b[38;5;241m.\u001b[39mlda_alpha)\n\u001b[0;32m     41\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m---> 42\u001b[0m     num_topics \u001b[38;5;241m=\u001b[39m topic_model\u001b[38;5;241m.\u001b[39mnum_topics\n\u001b[0;32m     44\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m doc_topic_dists \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m     45\u001b[0m     \u001b[38;5;66;03m# If its an HDP model.\u001b[39;00m\n\u001b[0;32m     46\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(topic_model, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mlda_beta\u001b[39m\u001b[38;5;124m'\u001b[39m):\n",
      "\u001b[1;31mAttributeError\u001b[0m: 'LatentDirichletAllocation' object has no attribute 'num_topics'"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.decomposition import LatentDirichletAllocation\n",
    "import pyLDAvis\n",
    "import pyLDAvis.gensim_models as gensimvis\n",
    "import gensim\n",
    "from gensim.matutils import Sparse2Corpus\n",
    "from gensim.corpora import Dictionary\n",
    "\n",
    "# Încarcă setul de date\n",
    "data = pd.read_csv('12000_lyrics_dataset.csv')\n",
    "\n",
    "# Elimină rândurile cu valori NaN în coloana 'Cleaned_Lyrics'\n",
    "data = data.dropna(subset=['Cleaned_Lyrics'])\n",
    "\n",
    "# Initializează vectorizatorul și modelul LDA\n",
    "vectorizer = CountVectorizer(max_df=0.95, min_df=2, stop_words='english')\n",
    "lda = LatentDirichletAllocation(n_components=10, random_state=0)\n",
    "\n",
    "# Vectorizează textele din coloana 'Cleaned_Lyrics'\n",
    "X = vectorizer.fit_transform(data['Cleaned_Lyrics'])\n",
    "\n",
    "# Antrenează modelul LDA pe datele vectorizate\n",
    "lda.fit(X)\n",
    "\n",
    "# Obține distribuția topic-urilor pentru fiecare instanță de versuri\n",
    "topic_distributions = lda.transform(X)\n",
    "\n",
    "# Identifică topic-ul dominant pentru fiecare instanță\n",
    "dominant_topics = topic_distributions.argmax(axis=1)\n",
    "\n",
    "# Adaugă topic-ul dominant la setul de date original\n",
    "data['topic_dominant'] = dominant_topics\n",
    "\n",
    "# Afișează rezultatele inițiale\n",
    "print(data[['Cleaned_Lyrics', 'Genre', 'topic_dominant']])\n",
    "\n",
    "# Funcție pentru a obține cuvintele cele mai relevante pentru fiecare topic\n",
    "def get_top_words(model, feature_names, n_top_words):\n",
    "    top_words = {}\n",
    "    for topic_idx, topic in enumerate(model.components_):\n",
    "        top_words[topic_idx] = [feature_names[i] for i in topic.argsort()[:-n_top_words - 1:-1]]\n",
    "    return top_words\n",
    "\n",
    "# Obține cuvintele corespunzătoare fiecărui topic\n",
    "feature_names = vectorizer.get_feature_names_out()\n",
    "top_words = get_top_words(lda, feature_names, 20)\n",
    "\n",
    "# Afișează cuvintele pentru fiecare topic (fără filtrare)\n",
    "print(\"Cuvintele pentru fiecare topic (fără filtrare):\")\n",
    "for topic, words in top_words.items():\n",
    "    print(f\"Topic {topic}: {', '.join(words)}\")\n",
    "\n",
    "# Salvează cuvintele pentru fiecare topic (fără filtrare) într-un fișier CSV\n",
    "with open('12000_top_words_without_filtering.csv', 'w') as f:\n",
    "    f.write(\"Topic,Words\\n\")\n",
    "    for topic, words in top_words.items():\n",
    "        f.write(f\"{topic},{', '.join(words)}\\n\")\n",
    "\n",
    "# Identifică cuvintele comune între topicuri\n",
    "word_counts = {}\n",
    "for words in top_words.values():\n",
    "    for word in words:\n",
    "        word_counts[word] = word_counts.get(word, 0) + 1\n",
    "\n",
    "# Elimină cuvintele comune între topicuri\n",
    "unique_top_words = {}\n",
    "for topic_idx, words in top_words.items():\n",
    "    unique_top_words[topic_idx] = [word for word in words if word_counts[word] == 1]\n",
    "\n",
    "# Afișează cuvintele filtrate pentru fiecare topic\n",
    "print(\"Cuvintele pentru fiecare topic (cu filtrare):\")\n",
    "for topic, words in unique_top_words.items():\n",
    "    print(f\"Topic {topic}: {', '.join(words)}\")\n",
    "\n",
    "# Salvează cuvintele pentru fiecare topic (cu filtrare) într-un fișier CSV\n",
    "with open('12000_top_words_with_filtering.csv', 'w') as f:\n",
    "    f.write(\"Topic,Words\\n\")\n",
    "    for topic, words in unique_top_words.items():\n",
    "        f.write(f\"{topic},{', '.join(words)}\\n\")\n",
    "\n",
    "# Analiza frecvenței topicurilor pe genuri\n",
    "topic_genre_distribution = data.groupby(['Genre', 'topic_dominant']).size().unstack(fill_value=0)\n",
    "\n",
    "# Afișează distribuția topicurilor pe genuri\n",
    "print(topic_genre_distribution)\n",
    "\n",
    "# Salvează distribuția topicurilor pe genuri într-un fișier CSV\n",
    "topic_genre_distribution.to_csv('12000_topic_genre_distribution.csv')\n",
    "\n",
    "# Salvează setul de date original cu topicurile dominante într-un fișier CSV\n",
    "data.to_csv('12000_lyrics_with_topics.csv', index=False)\n",
    "\n",
    "# Convert CountVectorizer result to a Gensim corpus and dictionary\n",
    "corpus = Sparse2Corpus(X, documents_columns=False)\n",
    "id2word = Dictionary.from_corpus(corpus, id2word=dict((i, s) for i, s in enumerate(vectorizer.get_feature_names_out())))\n",
    "\n",
    "# Vizualizarea topicurilor cu pyLDAvis\n",
    "pyLDAvis.enable_notebook()\n",
    "lda_display = gensimvis.prepare(lda, corpus, id2word, sort_topics=False)\n",
    "\n",
    "# Afișează vizualizarea\n",
    "pyLDAvis.show(lda_display)\n",
    "\n",
    "# Salvează vizualizarea în format HTML pentru a putea fi accesată ulterior\n",
    "pyLDAvis.save_html(lda_display, '12000_lda_visualization.html')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "359a921b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
